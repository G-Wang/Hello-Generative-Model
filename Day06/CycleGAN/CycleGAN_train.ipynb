{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cover](complements/cover.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from dataset import DatasetFromFolder\n",
    "from model import Generator, Discriminator\n",
    "\n",
    "import utils\n",
    "import argparse\n",
    "import os, itertools\n",
    "from logger import Logger\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Parsing & Directories Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=1, beta1=0.5, beta2=0.999, crop_size=256, dataset='horse2zebra', decay_epoch=100, fliplr=True, input_size=256, lambdaA=10, lambdaB=10, lrD=0.0002, lrG=0.0002, ndf=64, ngf=32, num_epochs=1, num_resnet=6, resize_scale=286)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "#Data Set Parameter\n",
    "parser.add_argument('--dataset', required=False, default='horse2zebra', help='input dataset')\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='train batch size')\n",
    "parser.add_argument('--input_size', type=int, default=256, help='input size')\n",
    "parser.add_argument('--resize_scale', type=int, default=286, help='resize scale (0 is false)')\n",
    "parser.add_argument('--crop_size', type=int, default=256, help='crop size (0 is false)')\n",
    "parser.add_argument('--fliplr', type=bool, default=True, help='random fliplr True of False')\n",
    "\n",
    "#Model Parameters \n",
    "parser.add_argument('--ngf', type=int, default=32) # number of generator filters\n",
    "parser.add_argument('--ndf', type=int, default=64) # number of discriminator filters\n",
    "parser.add_argument('--num_resnet', type=int, default=6, help='number of resnet blocks in generator')\n",
    "\n",
    "#Learning Parameters\n",
    "parser.add_argument('--num_epochs', type=int, default=30, help='number of train epochs')\n",
    "parser.add_argument('--decay_epoch', type=int, default=100, help='start decaying learning rate after this number')\n",
    "parser.add_argument('--lrG', type=float, default=0.0002, help='learning rate for generator, default=0.0002')\n",
    "parser.add_argument('--lrD', type=float, default=0.0002, help='learning rate for discriminator, default=0.0002')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for Adam optimizer')\n",
    "parser.add_argument('--beta2', type=float, default=0.999, help='beta2 for Adam optimizer')\n",
    "parser.add_argument('--lambdaA', type=float, default=10, help='lambdaA for cycle loss')\n",
    "parser.add_argument('--lambdaB', type=float, default=10, help='lambdaB for cycle loss')\n",
    "params = parser.parse_args([])\n",
    "print(params)\n",
    "\n",
    "# Directories for loading data and saving results\n",
    "data_dir = 'data/' + params.dataset + '/'\n",
    "save_dir = params.dataset + '_results/'\n",
    "model_dir = params.dataset + '_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dir) : \n",
    "    os.makedirs(data_dir)\n",
    "    file = 'ZIP_FILE.zip'\n",
    "    url = 'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/' + params.dataset + '.zip'\n",
    "    print(url)\n",
    "    !wget -N $url -O $file\n",
    "    !unzip $file -d 'data/'\n",
    "    !rm $file\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Set the logger\n",
    "D_A_log_dir = save_dir + 'D_A_logs'\n",
    "D_B_log_dir = save_dir + 'D_B_logs'\n",
    "if not os.path.exists(D_A_log_dir):\n",
    "    os.mkdir(D_A_log_dir)\n",
    "D_A_logger = Logger(D_A_log_dir)\n",
    "if not os.path.exists(D_B_log_dir):\n",
    "    os.mkdir(D_B_log_dir)\n",
    "D_B_logger = Logger(D_B_log_dir)\n",
    "\n",
    "G_A_log_dir = save_dir + 'G_A_logs'\n",
    "G_B_log_dir = save_dir + 'G_B_logs'\n",
    "if not os.path.exists(G_A_log_dir):\n",
    "    os.mkdir(G_A_log_dir)\n",
    "G_A_logger = Logger(G_A_log_dir)\n",
    "if not os.path.exists(G_B_log_dir):\n",
    "    os.mkdir(G_B_log_dir)\n",
    "G_B_logger = Logger(G_B_log_dir)\n",
    "\n",
    "cycle_A_log_dir = save_dir + 'cycle_A_logs'\n",
    "cycle_B_log_dir = save_dir + 'cycle_B_logs'\n",
    "if not os.path.exists(cycle_A_log_dir):\n",
    "    os.mkdir(cycle_A_log_dir)\n",
    "cycle_A_logger = Logger(cycle_A_log_dir)\n",
    "if not os.path.exists(cycle_B_log_dir):\n",
    "    os.mkdir(cycle_B_log_dir)\n",
    "cycle_B_logger = Logger(cycle_B_log_dir)\n",
    "\n",
    "img_log_dir = save_dir + 'img_logs'\n",
    "if not os.path.exists(img_log_dir):\n",
    "    os.mkdir(img_log_dir)\n",
    "img_logger = Logger(img_log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "transform = transforms.Compose([transforms.Resize(params.input_size),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "# Train data\n",
    "train_data_A = DatasetFromFolder(data_dir, subfolder='trainA', transform=transform,\n",
    "                                 resize_scale=params.resize_scale, crop_size=params.crop_size, fliplr=params.fliplr)\n",
    "train_data_loader_A = torch.utils.data.DataLoader(dataset=train_data_A,\n",
    "                                                  batch_size=params.batch_size,\n",
    "                                                  shuffle=True)\n",
    "train_data_B = DatasetFromFolder(data_dir, subfolder='trainB', transform=transform,\n",
    "                                 resize_scale=params.resize_scale, crop_size=params.crop_size, fliplr=params.fliplr)\n",
    "train_data_loader_B = torch.utils.data.DataLoader(dataset=train_data_B,\n",
    "                                                  batch_size=params.batch_size,\n",
    "                                                  shuffle=True)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# Test data\n",
    "test_data_A = DatasetFromFolder(data_dir, subfolder='testA', transform=transform)\n",
    "test_data_loader_A = torch.utils.data.DataLoader(dataset=test_data_A,\n",
    "                                                 batch_size=params.batch_size,\n",
    "                                                 shuffle=False)\n",
    "test_data_B = DatasetFromFolder(data_dir, subfolder='testB', transform=transform)\n",
    "test_data_loader_B = torch.utils.data.DataLoader(dataset=test_data_B,\n",
    "                                                 batch_size=params.batch_size,\n",
    "                                                 shuffle=False)\n",
    "\n",
    "# Get specific test images\n",
    "test_real_A_data = train_data_A.__getitem__(11).unsqueeze(0)  # Convert to 4d tensor (BxNxHxW)\n",
    "test_real_B_data = train_data_B.__getitem__(91).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models & Optimizers & Criterions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Models\n",
    "G_A = Generator(3, params.ngf, 3, params.num_resnet) # arguments : input_dim, num_filter, output_dim, num_resnet\n",
    "G_B = Generator(3, params.ngf, 3, params.num_resnet)\n",
    "D_A = Discriminator(3, params.ndf, 1)               # arguments : input_dim, num_filter, output_dim\n",
    "D_B = Discriminator(3, params.ndf, 1) \n",
    "\n",
    "G_A.normal_weight_init(mean=0.0, std=0.02)\n",
    "G_B.normal_weight_init(mean=0.0, std=0.02)\n",
    "D_A.normal_weight_init(mean=0.0, std=0.02)\n",
    "D_B.normal_weight_init(mean=0.0, std=0.02)\n",
    "\n",
    "G_A.cuda()\n",
    "G_B.cuda()\n",
    "D_A.cuda()\n",
    "D_B.cuda()\n",
    "\n",
    "# optimizers\n",
    "G_optimizer = torch.optim.Adam(itertools.chain(G_A.parameters(), G_B.parameters()), lr=params.lrG, betas=(params.beta1, params.beta2))\n",
    "D_A_optimizer = torch.optim.Adam(D_A.parameters(), lr=params.lrD, betas=(params.beta1, params.beta2))\n",
    "D_B_optimizer = torch.optim.Adam(D_B.parameters(), lr=params.lrD, betas=(params.beta1, params.beta2))\n",
    "\n",
    "# Loss function\n",
    "MSE_loss = torch.nn.MSELoss().cuda()\n",
    "L1_loss = torch.nn.L1Loss().cuda()\n",
    "\n",
    "# # Training GAN\n",
    "D_A_avg_losses = []\n",
    "D_B_avg_losses = []\n",
    "G_A_avg_losses = []\n",
    "G_B_avg_losses = []\n",
    "cycle_A_avg_losses = []\n",
    "cycle_B_avg_losses = []\n",
    "\n",
    "# Generated image pool\n",
    "num_pool = 50\n",
    "fake_A_pool = utils.ImagePool(num_pool)\n",
    "fake_B_pool = utils.ImagePool(num_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "<br><br>\n",
    "## Concepts\n",
    "![concept](complements/concept.jpg)\n",
    "<br>\n",
    "## GAN Losses\n",
    "![gan_loss](complements/gan_loss.JPG)\n",
    "<br>\n",
    "## Cycle Consistency Losses\n",
    "![cycle_consistency_loss](complements/cycle_consistency.JPG)\n",
    "<br>\n",
    "## Full Objectives = Gan Losses + Cycle Consistency Losses \n",
    "![full_objectives](complements/full_objectives.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/1067], D_A_loss: 0.7572, D_B_loss: 0.5360, G_A_loss: 0.9199, G_B_loss: 1.3571\n",
      "Epoch [1/1], Step [11/1067], D_A_loss: 0.2966, D_B_loss: 0.4281, G_A_loss: 0.4686, G_B_loss: 0.3903\n",
      "Epoch [1/1], Step [21/1067], D_A_loss: 0.3075, D_B_loss: 0.2699, G_A_loss: 0.3335, G_B_loss: 0.3478\n",
      "Epoch [1/1], Step [31/1067], D_A_loss: 0.2117, D_B_loss: 0.2828, G_A_loss: 0.3091, G_B_loss: 0.3918\n",
      "Epoch [1/1], Step [41/1067], D_A_loss: 0.2810, D_B_loss: 0.1995, G_A_loss: 0.3551, G_B_loss: 0.2603\n",
      "Epoch [1/1], Step [51/1067], D_A_loss: 0.2599, D_B_loss: 0.2508, G_A_loss: 0.3079, G_B_loss: 0.4972\n",
      "Epoch [1/1], Step [61/1067], D_A_loss: 0.1657, D_B_loss: 0.3117, G_A_loss: 0.1817, G_B_loss: 0.3903\n",
      "Epoch [1/1], Step [71/1067], D_A_loss: 0.2893, D_B_loss: 0.2302, G_A_loss: 0.3285, G_B_loss: 0.2182\n",
      "Epoch [1/1], Step [81/1067], D_A_loss: 0.1836, D_B_loss: 0.2592, G_A_loss: 0.3782, G_B_loss: 0.2973\n",
      "Epoch [1/1], Step [91/1067], D_A_loss: 0.2448, D_B_loss: 0.1890, G_A_loss: 0.4060, G_B_loss: 0.2271\n",
      "Epoch [1/1], Step [101/1067], D_A_loss: 0.2440, D_B_loss: 0.5934, G_A_loss: 0.5320, G_B_loss: 0.2709\n",
      "Epoch [1/1], Step [111/1067], D_A_loss: 0.2161, D_B_loss: 0.1999, G_A_loss: 0.3018, G_B_loss: 0.2559\n",
      "Epoch [1/1], Step [121/1067], D_A_loss: 0.2039, D_B_loss: 0.1674, G_A_loss: 0.3197, G_B_loss: 0.2556\n",
      "Epoch [1/1], Step [131/1067], D_A_loss: 0.2188, D_B_loss: 0.2060, G_A_loss: 0.3336, G_B_loss: 0.4580\n",
      "Epoch [1/1], Step [141/1067], D_A_loss: 0.2422, D_B_loss: 0.2409, G_A_loss: 0.4821, G_B_loss: 0.2041\n",
      "Epoch [1/1], Step [151/1067], D_A_loss: 0.2787, D_B_loss: 0.1227, G_A_loss: 0.2968, G_B_loss: 0.3140\n",
      "Epoch [1/1], Step [161/1067], D_A_loss: 0.2812, D_B_loss: 0.2309, G_A_loss: 0.4413, G_B_loss: 0.3726\n",
      "Epoch [1/1], Step [171/1067], D_A_loss: 0.1860, D_B_loss: 0.1857, G_A_loss: 0.3526, G_B_loss: 0.2506\n",
      "Epoch [1/1], Step [181/1067], D_A_loss: 0.2320, D_B_loss: 0.1470, G_A_loss: 0.4723, G_B_loss: 0.2829\n",
      "Epoch [1/1], Step [191/1067], D_A_loss: 0.2550, D_B_loss: 0.1932, G_A_loss: 0.3836, G_B_loss: 0.2329\n",
      "Epoch [1/1], Step [201/1067], D_A_loss: 0.2127, D_B_loss: 0.1539, G_A_loss: 0.2869, G_B_loss: 0.2815\n",
      "Epoch [1/1], Step [211/1067], D_A_loss: 0.1761, D_B_loss: 0.3018, G_A_loss: 0.3199, G_B_loss: 0.4399\n",
      "Epoch [1/1], Step [221/1067], D_A_loss: 0.2149, D_B_loss: 0.1093, G_A_loss: 0.1113, G_B_loss: 0.3519\n",
      "Epoch [1/1], Step [231/1067], D_A_loss: 0.1665, D_B_loss: 0.3173, G_A_loss: 0.1651, G_B_loss: 0.3519\n",
      "Epoch [1/1], Step [241/1067], D_A_loss: 0.1517, D_B_loss: 0.4443, G_A_loss: 0.6963, G_B_loss: 0.2555\n",
      "Epoch [1/1], Step [251/1067], D_A_loss: 0.2344, D_B_loss: 0.1383, G_A_loss: 0.4458, G_B_loss: 0.3556\n",
      "Epoch [1/1], Step [261/1067], D_A_loss: 0.2246, D_B_loss: 0.2247, G_A_loss: 0.2210, G_B_loss: 0.4410\n",
      "Epoch [1/1], Step [271/1067], D_A_loss: 0.3762, D_B_loss: 0.2585, G_A_loss: 0.4358, G_B_loss: 0.2053\n",
      "Epoch [1/1], Step [281/1067], D_A_loss: 0.1912, D_B_loss: 0.2572, G_A_loss: 0.1815, G_B_loss: 0.2961\n",
      "Epoch [1/1], Step [291/1067], D_A_loss: 0.2848, D_B_loss: 0.2516, G_A_loss: 0.7638, G_B_loss: 0.5274\n",
      "Epoch [1/1], Step [301/1067], D_A_loss: 0.3133, D_B_loss: 0.2341, G_A_loss: 0.3039, G_B_loss: 0.3481\n",
      "Epoch [1/1], Step [311/1067], D_A_loss: 0.2325, D_B_loss: 0.2208, G_A_loss: 0.2365, G_B_loss: 0.5188\n",
      "Epoch [1/1], Step [321/1067], D_A_loss: 0.1460, D_B_loss: 0.1401, G_A_loss: 0.3147, G_B_loss: 0.4806\n",
      "Epoch [1/1], Step [331/1067], D_A_loss: 0.2287, D_B_loss: 0.1226, G_A_loss: 0.2469, G_B_loss: 0.2470\n",
      "Epoch [1/1], Step [341/1067], D_A_loss: 0.2486, D_B_loss: 0.3127, G_A_loss: 0.9547, G_B_loss: 0.2069\n",
      "Epoch [1/1], Step [351/1067], D_A_loss: 0.2405, D_B_loss: 0.2035, G_A_loss: 0.6387, G_B_loss: 0.5158\n",
      "Epoch [1/1], Step [361/1067], D_A_loss: 0.2969, D_B_loss: 0.3066, G_A_loss: 0.1121, G_B_loss: 0.1592\n",
      "Epoch [1/1], Step [371/1067], D_A_loss: 0.2470, D_B_loss: 0.1306, G_A_loss: 0.2584, G_B_loss: 0.2489\n",
      "Epoch [1/1], Step [381/1067], D_A_loss: 0.3337, D_B_loss: 0.2190, G_A_loss: 0.1181, G_B_loss: 0.1335\n",
      "Epoch [1/1], Step [391/1067], D_A_loss: 0.1306, D_B_loss: 0.0679, G_A_loss: 0.2137, G_B_loss: 0.2278\n",
      "Epoch [1/1], Step [401/1067], D_A_loss: 0.5614, D_B_loss: 0.2286, G_A_loss: 0.2102, G_B_loss: 0.0542\n",
      "Epoch [1/1], Step [411/1067], D_A_loss: 0.2461, D_B_loss: 0.3427, G_A_loss: 0.3824, G_B_loss: 0.1805\n",
      "Epoch [1/1], Step [421/1067], D_A_loss: 0.1634, D_B_loss: 0.1792, G_A_loss: 0.4404, G_B_loss: 0.3670\n",
      "Epoch [1/1], Step [431/1067], D_A_loss: 0.1118, D_B_loss: 0.1285, G_A_loss: 0.3115, G_B_loss: 0.2105\n",
      "Epoch [1/1], Step [441/1067], D_A_loss: 0.2458, D_B_loss: 0.3079, G_A_loss: 0.1363, G_B_loss: 0.2342\n",
      "Epoch [1/1], Step [451/1067], D_A_loss: 0.1659, D_B_loss: 0.2784, G_A_loss: 0.6437, G_B_loss: 0.2342\n",
      "Epoch [1/1], Step [461/1067], D_A_loss: 0.1602, D_B_loss: 0.1579, G_A_loss: 0.5147, G_B_loss: 0.3832\n",
      "Epoch [1/1], Step [471/1067], D_A_loss: 0.1670, D_B_loss: 0.2093, G_A_loss: 0.0967, G_B_loss: 0.7489\n",
      "Epoch [1/1], Step [481/1067], D_A_loss: 0.3949, D_B_loss: 0.7339, G_A_loss: 0.1067, G_B_loss: 0.7092\n",
      "Epoch [1/1], Step [491/1067], D_A_loss: 0.1268, D_B_loss: 0.1856, G_A_loss: 0.3194, G_B_loss: 0.2533\n",
      "Epoch [1/1], Step [501/1067], D_A_loss: 0.3702, D_B_loss: 0.3510, G_A_loss: 0.1429, G_B_loss: 0.8382\n",
      "Epoch [1/1], Step [511/1067], D_A_loss: 0.2368, D_B_loss: 0.1544, G_A_loss: 0.3165, G_B_loss: 0.4500\n",
      "Epoch [1/1], Step [521/1067], D_A_loss: 0.2320, D_B_loss: 0.2975, G_A_loss: 0.1015, G_B_loss: 0.2772\n",
      "Epoch [1/1], Step [531/1067], D_A_loss: 0.2614, D_B_loss: 0.2090, G_A_loss: 0.3153, G_B_loss: 0.1393\n",
      "Epoch [1/1], Step [541/1067], D_A_loss: 0.2304, D_B_loss: 0.1002, G_A_loss: 0.3906, G_B_loss: 0.4047\n",
      "Epoch [1/1], Step [551/1067], D_A_loss: 0.1499, D_B_loss: 0.1132, G_A_loss: 0.2096, G_B_loss: 0.5001\n",
      "Epoch [1/1], Step [561/1067], D_A_loss: 0.3596, D_B_loss: 0.1319, G_A_loss: 0.4804, G_B_loss: 0.2052\n",
      "Epoch [1/1], Step [571/1067], D_A_loss: 0.1837, D_B_loss: 0.2266, G_A_loss: 0.1778, G_B_loss: 0.9100\n",
      "Epoch [1/1], Step [581/1067], D_A_loss: 0.1706, D_B_loss: 0.3374, G_A_loss: 0.2039, G_B_loss: 0.3636\n",
      "Epoch [1/1], Step [591/1067], D_A_loss: 0.2352, D_B_loss: 0.0802, G_A_loss: 0.6176, G_B_loss: 0.3109\n",
      "Epoch [1/1], Step [601/1067], D_A_loss: 0.1575, D_B_loss: 0.3190, G_A_loss: 0.1518, G_B_loss: 0.3720\n",
      "Epoch [1/1], Step [611/1067], D_A_loss: 0.0864, D_B_loss: 0.0925, G_A_loss: 0.2463, G_B_loss: 0.5503\n",
      "Epoch [1/1], Step [621/1067], D_A_loss: 0.1288, D_B_loss: 0.1493, G_A_loss: 0.2759, G_B_loss: 0.4700\n",
      "Epoch [1/1], Step [631/1067], D_A_loss: 0.2197, D_B_loss: 0.2114, G_A_loss: 0.2011, G_B_loss: 0.5512\n",
      "Epoch [1/1], Step [641/1067], D_A_loss: 0.2206, D_B_loss: 0.1197, G_A_loss: 0.3427, G_B_loss: 1.1251\n",
      "Epoch [1/1], Step [651/1067], D_A_loss: 0.0976, D_B_loss: 0.1803, G_A_loss: 0.3924, G_B_loss: 0.4059\n",
      "Epoch [1/1], Step [661/1067], D_A_loss: 0.1859, D_B_loss: 0.1763, G_A_loss: 0.2449, G_B_loss: 0.2179\n",
      "Epoch [1/1], Step [671/1067], D_A_loss: 0.0554, D_B_loss: 0.0365, G_A_loss: 0.2382, G_B_loss: 0.3615\n",
      "Epoch [1/1], Step [681/1067], D_A_loss: 0.2275, D_B_loss: 0.2481, G_A_loss: 0.2913, G_B_loss: 0.6997\n",
      "Epoch [1/1], Step [691/1067], D_A_loss: 0.1479, D_B_loss: 0.0867, G_A_loss: 0.2616, G_B_loss: 0.5582\n",
      "Epoch [1/1], Step [701/1067], D_A_loss: 0.1908, D_B_loss: 0.1454, G_A_loss: 0.2117, G_B_loss: 0.8077\n",
      "Epoch [1/1], Step [711/1067], D_A_loss: 0.1210, D_B_loss: 0.0800, G_A_loss: 0.6035, G_B_loss: 0.8082\n",
      "Epoch [1/1], Step [721/1067], D_A_loss: 0.1493, D_B_loss: 0.5134, G_A_loss: 0.8399, G_B_loss: 0.2517\n",
      "Epoch [1/1], Step [731/1067], D_A_loss: 0.1921, D_B_loss: 0.4417, G_A_loss: 0.0588, G_B_loss: 0.9998\n",
      "Epoch [1/1], Step [741/1067], D_A_loss: 0.1478, D_B_loss: 0.1964, G_A_loss: 0.3847, G_B_loss: 0.0368\n",
      "Epoch [1/1], Step [751/1067], D_A_loss: 0.1361, D_B_loss: 0.1480, G_A_loss: 0.2880, G_B_loss: 0.8080\n",
      "Epoch [1/1], Step [761/1067], D_A_loss: 0.1737, D_B_loss: 0.1167, G_A_loss: 0.0838, G_B_loss: 0.1314\n",
      "Epoch [1/1], Step [771/1067], D_A_loss: 0.1803, D_B_loss: 0.2121, G_A_loss: 0.5499, G_B_loss: 0.2187\n",
      "Epoch [1/1], Step [781/1067], D_A_loss: 0.3162, D_B_loss: 0.2691, G_A_loss: 0.1471, G_B_loss: 0.0888\n",
      "Epoch [1/1], Step [791/1067], D_A_loss: 0.2367, D_B_loss: 0.4161, G_A_loss: 0.8729, G_B_loss: 0.3688\n",
      "Epoch [1/1], Step [801/1067], D_A_loss: 0.1056, D_B_loss: 0.3699, G_A_loss: 0.0905, G_B_loss: 0.4247\n",
      "Epoch [1/1], Step [811/1067], D_A_loss: 0.2365, D_B_loss: 0.1193, G_A_loss: 0.4651, G_B_loss: 0.1825\n",
      "Epoch [1/1], Step [821/1067], D_A_loss: 0.0797, D_B_loss: 0.1298, G_A_loss: 0.2002, G_B_loss: 0.4649\n",
      "Epoch [1/1], Step [831/1067], D_A_loss: 0.3956, D_B_loss: 0.2144, G_A_loss: 0.8713, G_B_loss: 0.1684\n",
      "Epoch [1/1], Step [841/1067], D_A_loss: 0.0842, D_B_loss: 0.1397, G_A_loss: 0.4418, G_B_loss: 0.5357\n",
      "Epoch [1/1], Step [851/1067], D_A_loss: 0.1449, D_B_loss: 0.2805, G_A_loss: 0.9010, G_B_loss: 0.7100\n",
      "Epoch [1/1], Step [861/1067], D_A_loss: 0.2044, D_B_loss: 0.3314, G_A_loss: 0.0654, G_B_loss: 0.2009\n",
      "Epoch [1/1], Step [871/1067], D_A_loss: 0.1359, D_B_loss: 0.3108, G_A_loss: 0.2752, G_B_loss: 0.2438\n",
      "Epoch [1/1], Step [881/1067], D_A_loss: 0.2249, D_B_loss: 0.0720, G_A_loss: 0.4361, G_B_loss: 0.6133\n",
      "Epoch [1/1], Step [891/1067], D_A_loss: 0.1199, D_B_loss: 0.4103, G_A_loss: 0.1966, G_B_loss: 0.2034\n",
      "Epoch [1/1], Step [901/1067], D_A_loss: 0.1473, D_B_loss: 0.1891, G_A_loss: 0.8556, G_B_loss: 0.3872\n",
      "Epoch [1/1], Step [911/1067], D_A_loss: 0.1379, D_B_loss: 0.1153, G_A_loss: 0.2731, G_B_loss: 0.7108\n",
      "Epoch [1/1], Step [921/1067], D_A_loss: 0.0395, D_B_loss: 0.2346, G_A_loss: 0.1394, G_B_loss: 0.1705\n",
      "Epoch [1/1], Step [931/1067], D_A_loss: 0.1156, D_B_loss: 0.1415, G_A_loss: 0.3543, G_B_loss: 0.7132\n",
      "Epoch [1/1], Step [941/1067], D_A_loss: 0.0792, D_B_loss: 0.3600, G_A_loss: 0.7901, G_B_loss: 0.4000\n",
      "Epoch [1/1], Step [951/1067], D_A_loss: 0.0731, D_B_loss: 0.1123, G_A_loss: 0.3671, G_B_loss: 0.3316\n",
      "Epoch [1/1], Step [961/1067], D_A_loss: 0.1773, D_B_loss: 0.1274, G_A_loss: 0.2065, G_B_loss: 0.5992\n",
      "Epoch [1/1], Step [971/1067], D_A_loss: 0.1168, D_B_loss: 0.1330, G_A_loss: 0.2107, G_B_loss: 0.5854\n",
      "Epoch [1/1], Step [981/1067], D_A_loss: 0.1338, D_B_loss: 0.2452, G_A_loss: 0.1417, G_B_loss: 0.5140\n",
      "Epoch [1/1], Step [991/1067], D_A_loss: 0.2831, D_B_loss: 0.1743, G_A_loss: 0.3516, G_B_loss: 0.3570\n",
      "Epoch [1/1], Step [1001/1067], D_A_loss: 0.0935, D_B_loss: 0.1174, G_A_loss: 0.4169, G_B_loss: 0.4916\n",
      "Epoch [1/1], Step [1011/1067], D_A_loss: 0.0466, D_B_loss: 0.1035, G_A_loss: 0.1975, G_B_loss: 0.3049\n",
      "Epoch [1/1], Step [1021/1067], D_A_loss: 0.2702, D_B_loss: 0.2090, G_A_loss: 0.3509, G_B_loss: 0.9108\n",
      "Epoch [1/1], Step [1031/1067], D_A_loss: 0.1229, D_B_loss: 0.0697, G_A_loss: 0.0249, G_B_loss: 0.2777\n",
      "Epoch [1/1], Step [1041/1067], D_A_loss: 0.4076, D_B_loss: 0.3623, G_A_loss: 0.0708, G_B_loss: 0.0508\n",
      "Epoch [1/1], Step [1051/1067], D_A_loss: 0.1805, D_B_loss: 0.2104, G_A_loss: 0.2120, G_B_loss: 0.2793\n",
      "Epoch [1/1], Step [1061/1067], D_A_loss: 0.1241, D_B_loss: 0.1651, G_A_loss: 0.4468, G_B_loss: 0.2516\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "for epoch in range(params.num_epochs):\n",
    "    D_A_losses = []\n",
    "    D_B_losses = []\n",
    "    G_A_losses = []\n",
    "    G_B_losses = []\n",
    "    cycle_A_losses = []\n",
    "    cycle_B_losses = []\n",
    "\n",
    "    # learning rate decay\n",
    "    if (epoch + 1) > params.decay_epoch:\n",
    "        D_A_optimizer.param_groups[0]['lr'] -= params.lrD / (params.num_epochs - params.decay_epoch)\n",
    "        D_B_optimizer.param_groups[0]['lr'] -= params.lrD / (params.num_epochs - params.decay_epoch)\n",
    "        G_optimizer.param_groups[0]['lr'] -= params.lrG / (params.num_epochs - params.decay_epoch)\n",
    "\n",
    "    # training\n",
    "    for i, (real_A, real_B) in enumerate(zip(train_data_loader_A, train_data_loader_B)):\n",
    "\n",
    "        # input image data\n",
    "        real_A = real_A.cuda()\n",
    "        real_B = real_B.cuda()\n",
    "\n",
    "        # ------------------------ Train generator G ----------------------------\n",
    "        # A -> B\n",
    "        fake_B = G_A(real_A)\n",
    "        D_B_fake_decision = D_B(fake_B)\n",
    "        G_A_loss = MSE_loss(D_B_fake_decision, torch.ones(D_B_fake_decision.size()).cuda())\n",
    "\n",
    "        # forward cycle loss\n",
    "        recon_A = G_B(fake_B)\n",
    "        cycle_A_loss = L1_loss(recon_A, real_A) * params.lambdaA\n",
    "\n",
    "        # B -> A\n",
    "        fake_A = G_B(real_B)\n",
    "        D_A_fake_decision = D_A(fake_A)\n",
    "        G_B_loss = MSE_loss(D_A_fake_decision, torch.ones(D_A_fake_decision.size()).cuda())\n",
    "\n",
    "        # backward cycle loss\n",
    "        recon_B = G_A(fake_A)\n",
    "        cycle_B_loss = L1_loss(recon_B, real_B) * params.lambdaB\n",
    "\n",
    "        # Back propagation\n",
    "        G_loss = G_A_loss + G_B_loss + cycle_A_loss + cycle_B_loss\n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        \n",
    "        # ------------------------ Train discriminator D_A ------------------------\n",
    "        D_A_real_decision = D_A(real_A)\n",
    "        D_A_real_loss = MSE_loss(D_A_real_decision, torch.ones(D_A_real_decision.size()).cuda())\n",
    "        \n",
    "        fake_A = fake_A_pool.query(fake_A)\n",
    "        \n",
    "        D_A_fake_decision = D_A(fake_A)\n",
    "        D_A_fake_loss = MSE_loss(D_A_fake_decision, torch.zeros(D_A_fake_decision.size()).cuda())\n",
    "\n",
    "        # Back propagation\n",
    "        D_A_loss = (D_A_real_loss + D_A_fake_loss) * 0.5\n",
    "        D_A_optimizer.zero_grad()\n",
    "        D_A_loss.backward()\n",
    "        D_A_optimizer.step()\n",
    "\n",
    "        # ------------------------ Train discriminator D_B ------------------------\n",
    "        D_B_real_decision = D_B(real_B)\n",
    "        D_B_real_loss = MSE_loss(D_B_real_decision, torch.ones(D_B_real_decision.size()).cuda())\n",
    "        fake_B = fake_B_pool.query(fake_B)\n",
    "        D_B_fake_decision = D_B(fake_B)\n",
    "        D_B_fake_loss = MSE_loss(D_B_fake_decision, torch.zeros(D_B_fake_decision.size()).cuda())\n",
    "\n",
    "        # Back propagation\n",
    "        D_B_loss = (D_B_real_loss + D_B_fake_loss) * 0.5\n",
    "        D_B_optimizer.zero_grad()\n",
    "        D_B_loss.backward()\n",
    "        D_B_optimizer.step()\n",
    "\n",
    "        # ------------------------ Print -----------------------------\n",
    "        # loss values\n",
    "        D_A_losses.append(D_A_loss.item())\n",
    "        D_B_losses.append(D_B_loss.item())\n",
    "        G_A_losses.append(G_A_loss.item())\n",
    "        G_B_losses.append(G_B_loss.item())\n",
    "        cycle_A_losses.append(cycle_A_loss.item())\n",
    "        cycle_B_losses.append(cycle_B_loss.item())\n",
    "\n",
    "        if i%10 == 0:\n",
    "            print('Epoch [%d/%d], Step [%d/%d], D_A_loss: %.4f, D_B_loss: %.4f, G_A_loss: %.4f, G_B_loss: %.4f'\n",
    "                  % (epoch+1, params.num_epochs, i+1, len(train_data_loader_A), D_A_loss.item(), D_B_loss.item(), G_A_loss.item(), G_B_loss.item()))\n",
    "\n",
    "        # ============ TensorBoard logging ============#\n",
    "        D_A_logger.scalar_summary('losses', D_A_loss.item(), step + 1)\n",
    "        D_B_logger.scalar_summary('losses', D_B_loss.item(), step + 1)\n",
    "        G_A_logger.scalar_summary('losses', G_A_loss.item(), step + 1)\n",
    "        G_B_logger.scalar_summary('losses', G_B_loss.item(), step + 1)\n",
    "        cycle_A_logger.scalar_summary('losses', cycle_A_loss.item(), step + 1)\n",
    "        cycle_B_logger.scalar_summary('losses', cycle_B_loss.item(), step + 1)\n",
    "        step += 1\n",
    "\n",
    "    D_A_avg_loss = torch.mean(torch.FloatTensor(D_A_losses))\n",
    "    D_B_avg_loss = torch.mean(torch.FloatTensor(D_B_losses))\n",
    "    G_A_avg_loss = torch.mean(torch.FloatTensor(G_A_losses))\n",
    "    G_B_avg_loss = torch.mean(torch.FloatTensor(G_B_losses))\n",
    "    cycle_A_avg_loss = torch.mean(torch.FloatTensor(cycle_A_losses))\n",
    "    cycle_B_avg_loss = torch.mean(torch.FloatTensor(cycle_B_losses))\n",
    "\n",
    "    # avg loss values for plot\n",
    "    D_A_avg_losses.append(D_A_avg_loss)\n",
    "    D_B_avg_losses.append(D_B_avg_loss)\n",
    "    G_A_avg_losses.append(G_A_avg_loss)\n",
    "    G_B_avg_losses.append(G_B_avg_loss)\n",
    "    cycle_A_avg_losses.append(cycle_A_avg_loss)\n",
    "    cycle_B_avg_losses.append(cycle_B_avg_loss)\n",
    "\n",
    "    # Show result for test image\n",
    "    test_real_A = test_real_A_data.cuda()\n",
    "    test_fake_B = G_A(test_real_A)\n",
    "    test_recon_A = G_B(test_fake_B)\n",
    "\n",
    "    test_real_B = test_real_B_data.cuda()\n",
    "    test_fake_A = G_B(test_real_B)\n",
    "    test_recon_B = G_A(test_fake_A)\n",
    "\n",
    "    utils.plot_train_result([test_real_A, test_real_B], [test_fake_B, test_fake_A], [test_recon_A, test_recon_B],\n",
    "                            epoch, save=True, save_dir=save_dir)\n",
    "\n",
    "    # log the images\n",
    "    result_AtoB = np.concatenate((utils.to_np(test_real_A), utils.to_np(test_fake_B), utils.to_np(test_recon_A)), axis=3)\n",
    "    result_BtoA = np.concatenate((utils.to_np(test_real_B), utils.to_np(test_fake_A), utils.to_np(test_recon_B)), axis=3)\n",
    "\n",
    "    info = { 'result_AtoB': result_AtoB.transpose(0, 2, 3, 1),  # convert to BxHxWxC\n",
    "             'result_BtoA': result_BtoA.transpose(0, 2, 3, 1) }\n",
    "\n",
    "    for tag, images in info.items():\n",
    "        img_logger.image_summary(tag, images, epoch + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average losses\n",
    "avg_losses = []\n",
    "avg_losses.append(D_A_avg_losses)\n",
    "avg_losses.append(D_B_avg_losses)\n",
    "avg_losses.append(G_A_avg_losses)\n",
    "avg_losses.append(G_B_avg_losses)\n",
    "avg_losses.append(cycle_A_avg_losses)\n",
    "avg_losses.append(cycle_B_avg_losses)\n",
    "utils.plot_loss(avg_losses, params.num_epochs, save=True, save_dir=save_dir)\n",
    "\n",
    "# Make gif\n",
    "utils.make_gif(params.dataset, params.num_epochs, save_dir=save_dir)\n",
    "# Save trained parameters of model\n",
    "torch.save(G_A.state_dict(), model_dir + 'generator_A_param.pkl')\n",
    "torch.save(G_B.state_dict(), model_dir + 'generator_B_param.pkl')\n",
    "torch.save(D_A.state_dict(), model_dir + 'discriminator_A_param.pkl')\n",
    "torch.save(D_B.state_dict(), model_dir + 'discriminator_B_param.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
