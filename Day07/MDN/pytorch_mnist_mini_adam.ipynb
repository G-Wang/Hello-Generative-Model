{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import codecs\n",
    "import copy\n",
    "\n",
    "# 랜덤 시드 설정.\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset 코드\n",
    "pytorch의 torchvision 패키지에 기본으로 들어가 있는 MNIST 클래스는 train/test 셋으로만 되어 있음.\n",
    "train/val/test 셋으로 다시 나눠주기 위해 하드코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNIST(torch.utils.data.Dataset):\n",
    "  \"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
    "  Args:\n",
    "    root (string): Root directory of dataset where ``processed/training.pt``\n",
    "      and  ``processed/test.pt`` exist.\n",
    "    dataset (string): If `train` or `valid`, creates dataset from ``training.pt``,\n",
    "      otherwise from ``test.pt``.\n",
    "    download (bool, optional): If true, downloads the dataset from the internet and\n",
    "      puts it in root directory. If dataset is already downloaded, it is not\n",
    "      downloaded again.\n",
    "    transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "      and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "    target_transform (callable, optional): A function/transform that takes in the\n",
    "      target and transforms it.\n",
    "  \"\"\"\n",
    "  urls = [\n",
    "    'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "    'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "    'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "    'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "  ]\n",
    "  raw_folder = 'raw'\n",
    "  processed_folder = 'processed'\n",
    "  training_file = 'training.pt'\n",
    "  test_file = 'test.pt'\n",
    "\n",
    "  def __init__(self, root, dataset='train', transform=None, target_transform=None, download=False):\n",
    "    self.root = os.path.expanduser(root)\n",
    "    self.transform = transform\n",
    "    self.target_transform = target_transform\n",
    "    self.dataset = dataset  # 'train', 'valid', or 'test'\n",
    "    self.cutoff = 50000 # split between train vs validation\n",
    "\n",
    "    if download:\n",
    "      self.download()\n",
    "\n",
    "    if not self._check_exists():\n",
    "      raise RuntimeError('Dataset not found.' +\n",
    "                        ' You can use download=True to download it')\n",
    "\n",
    "    if self.dataset == 'train' or self.dataset == 'valid':\n",
    "      full_train_data, full_train_labels = torch.load(os.path.join(root, self.processed_folder, self.training_file))\n",
    "      if self.dataset == 'train':\n",
    "        self.data = full_train_data[:self.cutoff]\n",
    "        self.labels = full_train_labels[:self.cutoff]\n",
    "      else:\n",
    "        self.data = full_train_data[self.cutoff:]\n",
    "        self.labels = full_train_labels[self.cutoff:]\n",
    "    else:\n",
    "      self.data, self.labels = torch.load(os.path.join(root, self.processed_folder, self.test_file))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      \"\"\"\n",
    "      Args:\n",
    "        index (int): Index\n",
    "      Returns:\n",
    "        tuple: (image, target) where target is index of the target class.\n",
    "      \"\"\"\n",
    "      img, target = self.data[index], self.labels[index]\n",
    "\n",
    "      # doing this so that it is consistent with all other datasets\n",
    "      # to return a PIL Image\n",
    "      img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "      if self.transform is not None:\n",
    "        img = self.transform(img)\n",
    "\n",
    "      if self.target_transform is not None:\n",
    "        target = self.target_transform(target)\n",
    "\n",
    "      return img, target\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def _check_exists(self):\n",
    "    return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
    "      os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "\n",
    "  def download(self):\n",
    "    \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
    "    from six.moves import urllib\n",
    "    import gzip\n",
    "\n",
    "    if self._check_exists():\n",
    "      return\n",
    "\n",
    "    # download files\n",
    "    try:\n",
    "      os.makedirs(os.path.join(self.root, self.raw_folder))\n",
    "      os.makedirs(os.path.join(self.root, self.processed_folder))\n",
    "    except OSError as e:\n",
    "      if e.errno == errno.EEXIST:\n",
    "        pass\n",
    "      else:\n",
    "        raise\n",
    "\n",
    "    for url in self.urls:\n",
    "      print('Downloading ' + url)\n",
    "      data = urllib.request.urlopen(url)\n",
    "      filename = url.rpartition('/')[2]\n",
    "      file_path = os.path.join(self.root, self.raw_folder, filename)\n",
    "      with open(file_path, 'wb') as f:\n",
    "          f.write(data.read())\n",
    "      with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "              gzip.GzipFile(file_path) as zip_f:\n",
    "          out_f.write(zip_f.read())\n",
    "      os.unlink(file_path)\n",
    "\n",
    "    # process and save as torch files\n",
    "    print('Processing...')\n",
    "\n",
    "    training_set = (\n",
    "      read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
    "      read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
    "    )\n",
    "    test_set = (\n",
    "      read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
    "      read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
    "    )\n",
    "    with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
    "      torch.save(training_set, f)\n",
    "    with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
    "      torch.save(test_set, f)\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "\n",
    "def get_int(b):\n",
    "  return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "\n",
    "def parse_byte(b):\n",
    "  if isinstance(b, str):\n",
    "    return ord(b)\n",
    "  return b\n",
    "\n",
    "\n",
    "def read_label_file(path):\n",
    "  with open(path, 'rb') as f:\n",
    "    data = f.read()\n",
    "    assert get_int(data[:4]) == 2049\n",
    "    length = get_int(data[4:8])\n",
    "    labels = [parse_byte(b) for b in data[8:]]\n",
    "    assert len(labels) == length\n",
    "    return torch.LongTensor(labels)\n",
    "\n",
    "\n",
    "def read_image_file(path):\n",
    "  with open(path, 'rb') as f:\n",
    "    data = f.read()\n",
    "    assert get_int(data[:4]) == 2051\n",
    "    length = get_int(data[4:8])\n",
    "    num_rows = get_int(data[8:12])\n",
    "    num_cols = get_int(data[12:16])\n",
    "    images = []\n",
    "    idx = 16\n",
    "    for l in range(length):\n",
    "      img = []\n",
    "      images.append(img)\n",
    "      for r in range(num_rows):\n",
    "        row = []\n",
    "        img.append(row)\n",
    "        for c in range(num_cols):\n",
    "          row.append(parse_byte(data[idx]))\n",
    "          idx += 1\n",
    "    assert len(images) == length\n",
    "    return torch.ByteTensor(images).view(-1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = namedtuple('Args', ['batch_size', 'test_batch_size', 'epochs', 'lr', 'cuda', 'seed', 'log_interval'])\n",
    "args = Args(batch_size=1000, test_batch_size=1000, epochs=30, lr=0.001, cuda=True, seed=0, log_interval=10)\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "  torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  MNIST('MNIST_data', dataset='train', download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "  batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "  MNIST('MNIST_data', dataset='valid', download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "  batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  MNIST('MNIST_data', dataset='test', transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "  batch_size=args.batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.num_filter1 = 8\n",
    "    self.num_filter2 = 16\n",
    "    self.num_padding = 2\n",
    "    # input is 28x28\n",
    "    # padding=2 for same padding\n",
    "    self.conv1 = nn.Conv2d(1, self.num_filter1, 5, padding=self.num_padding)\n",
    "    # feature map size is 14*14 by pooling\n",
    "    # padding=2 for same padding\n",
    "    self.conv2 = nn.Conv2d(self.num_filter1, self.num_filter2, 5, padding=self.num_padding)\n",
    "    # feature map size is 7*7 by pooling\n",
    "    self.fc = nn.Linear(self.num_filter2*7*7, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "    x = x.view(-1, self.num_filter2*7*7)   # reshape Variable\n",
    "    x = self.fc(x)\n",
    "    return F.log_softmax(x)\n",
    "\n",
    "\n",
    "model = Net()\n",
    "if args.cuda:\n",
    "  model.cuda()\n",
    "\n",
    "orig_model = copy.deepcopy(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader):\n",
    "  model.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    if args.cuda:\n",
    "      data, target = data.cuda(), target.cuda()\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % args.log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  for data, target in test_loader:\n",
    "    if args.cuda:\n",
    "      data, target = data.cuda(), target.cuda()\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    output = model(data)\n",
    "    test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "    pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  acc = correct / len(test_loader.dataset)\n",
    "  print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * acc))\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.303826\n",
      "Train Epoch: 1 [10000/50000 (20%)]\tLoss: 1.677860\n",
      "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 0.841788\n",
      "Train Epoch: 1 [30000/50000 (60%)]\tLoss: 0.508113\n",
      "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 0.429082\n",
      "\n",
      "Average loss: 0.3061, Accuracy: 9138/10000 (91.3800%)\n",
      "\n",
      "best valid_acc 91.38\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.322197\n",
      "Train Epoch: 2 [10000/50000 (20%)]\tLoss: 0.280511\n",
      "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 0.266064\n",
      "Train Epoch: 2 [30000/50000 (60%)]\tLoss: 0.249114\n",
      "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 0.212269\n",
      "\n",
      "Average loss: 0.1894, Accuracy: 9463/10000 (94.6300%)\n",
      "\n",
      "best valid_acc 94.63000000000001\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.169653\n",
      "Train Epoch: 3 [10000/50000 (20%)]\tLoss: 0.187885\n",
      "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 0.179227\n",
      "Train Epoch: 3 [30000/50000 (60%)]\tLoss: 0.184279\n",
      "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 0.199606\n",
      "\n",
      "Average loss: 0.1434, Accuracy: 9611/10000 (96.1100%)\n",
      "\n",
      "best valid_acc 96.11\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.142613\n",
      "Train Epoch: 4 [10000/50000 (20%)]\tLoss: 0.128813\n",
      "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 0.115739\n",
      "Train Epoch: 4 [30000/50000 (60%)]\tLoss: 0.123765\n",
      "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 0.124982\n",
      "\n",
      "Average loss: 0.1124, Accuracy: 9696/10000 (96.9600%)\n",
      "\n",
      "best valid_acc 96.96000000000001\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.103703\n",
      "Train Epoch: 5 [10000/50000 (20%)]\tLoss: 0.092252\n",
      "Train Epoch: 5 [20000/50000 (40%)]\tLoss: 0.103819\n",
      "Train Epoch: 5 [30000/50000 (60%)]\tLoss: 0.079855\n",
      "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 0.092892\n",
      "\n",
      "Average loss: 0.0918, Accuracy: 9739/10000 (97.3900%)\n",
      "\n",
      "best valid_acc 97.39\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.083163\n",
      "Train Epoch: 6 [10000/50000 (20%)]\tLoss: 0.110554\n",
      "Train Epoch: 6 [20000/50000 (40%)]\tLoss: 0.093397\n",
      "Train Epoch: 6 [30000/50000 (60%)]\tLoss: 0.074999\n",
      "Train Epoch: 6 [40000/50000 (80%)]\tLoss: 0.095199\n",
      "\n",
      "Average loss: 0.0791, Accuracy: 9771/10000 (97.7100%)\n",
      "\n",
      "best valid_acc 97.71\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.069589\n",
      "Train Epoch: 7 [10000/50000 (20%)]\tLoss: 0.061731\n",
      "Train Epoch: 7 [20000/50000 (40%)]\tLoss: 0.079045\n",
      "Train Epoch: 7 [30000/50000 (60%)]\tLoss: 0.059712\n",
      "Train Epoch: 7 [40000/50000 (80%)]\tLoss: 0.084312\n",
      "\n",
      "Average loss: 0.0741, Accuracy: 9787/10000 (97.8700%)\n",
      "\n",
      "best valid_acc 97.87\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.073273\n",
      "Train Epoch: 8 [10000/50000 (20%)]\tLoss: 0.081892\n",
      "Train Epoch: 8 [20000/50000 (40%)]\tLoss: 0.082444\n",
      "Train Epoch: 8 [30000/50000 (60%)]\tLoss: 0.068969\n",
      "Train Epoch: 8 [40000/50000 (80%)]\tLoss: 0.063710\n",
      "\n",
      "Average loss: 0.0691, Accuracy: 9792/10000 (97.9200%)\n",
      "\n",
      "best valid_acc 97.92\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.064322\n",
      "Train Epoch: 9 [10000/50000 (20%)]\tLoss: 0.065069\n",
      "Train Epoch: 9 [20000/50000 (40%)]\tLoss: 0.069374\n",
      "Train Epoch: 9 [30000/50000 (60%)]\tLoss: 0.041568\n",
      "Train Epoch: 9 [40000/50000 (80%)]\tLoss: 0.066125\n",
      "\n",
      "Average loss: 0.0631, Accuracy: 9816/10000 (98.1600%)\n",
      "\n",
      "best valid_acc 98.16\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.058409\n",
      "Train Epoch: 10 [10000/50000 (20%)]\tLoss: 0.061789\n",
      "Train Epoch: 10 [20000/50000 (40%)]\tLoss: 0.037719\n",
      "Train Epoch: 10 [30000/50000 (60%)]\tLoss: 0.068512\n",
      "Train Epoch: 10 [40000/50000 (80%)]\tLoss: 0.063026\n",
      "\n",
      "Average loss: 0.0604, Accuracy: 9815/10000 (98.1500%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.038812\n",
      "Train Epoch: 11 [10000/50000 (20%)]\tLoss: 0.064404\n",
      "Train Epoch: 11 [20000/50000 (40%)]\tLoss: 0.044090\n",
      "Train Epoch: 11 [30000/50000 (60%)]\tLoss: 0.053269\n",
      "Train Epoch: 11 [40000/50000 (80%)]\tLoss: 0.041884\n",
      "\n",
      "Average loss: 0.0586, Accuracy: 9827/10000 (98.2700%)\n",
      "\n",
      "best valid_acc 98.27\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.029958\n",
      "Train Epoch: 12 [10000/50000 (20%)]\tLoss: 0.033014\n",
      "Train Epoch: 12 [20000/50000 (40%)]\tLoss: 0.041537\n",
      "Train Epoch: 12 [30000/50000 (60%)]\tLoss: 0.067422\n",
      "Train Epoch: 12 [40000/50000 (80%)]\tLoss: 0.058207\n",
      "\n",
      "Average loss: 0.0534, Accuracy: 9839/10000 (98.3900%)\n",
      "\n",
      "best valid_acc 98.39\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.036027\n",
      "Train Epoch: 13 [10000/50000 (20%)]\tLoss: 0.057380\n",
      "Train Epoch: 13 [20000/50000 (40%)]\tLoss: 0.058421\n",
      "Train Epoch: 13 [30000/50000 (60%)]\tLoss: 0.077929\n",
      "Train Epoch: 13 [40000/50000 (80%)]\tLoss: 0.033586\n",
      "\n",
      "Average loss: 0.0561, Accuracy: 9832/10000 (98.3200%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.044378\n",
      "Train Epoch: 14 [10000/50000 (20%)]\tLoss: 0.049616\n",
      "Train Epoch: 14 [20000/50000 (40%)]\tLoss: 0.032236\n",
      "Train Epoch: 14 [30000/50000 (60%)]\tLoss: 0.036111\n",
      "Train Epoch: 14 [40000/50000 (80%)]\tLoss: 0.031647\n",
      "\n",
      "Average loss: 0.0522, Accuracy: 9849/10000 (98.4900%)\n",
      "\n",
      "best valid_acc 98.49\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.034754\n",
      "Train Epoch: 15 [10000/50000 (20%)]\tLoss: 0.046193\n",
      "Train Epoch: 15 [20000/50000 (40%)]\tLoss: 0.041963\n",
      "Train Epoch: 15 [30000/50000 (60%)]\tLoss: 0.027877\n",
      "Train Epoch: 15 [40000/50000 (80%)]\tLoss: 0.033310\n",
      "\n",
      "Average loss: 0.0552, Accuracy: 9841/10000 (98.4100%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.031574\n",
      "Train Epoch: 16 [10000/50000 (20%)]\tLoss: 0.035795\n",
      "Train Epoch: 16 [20000/50000 (40%)]\tLoss: 0.057611\n",
      "Train Epoch: 16 [30000/50000 (60%)]\tLoss: 0.042014\n",
      "Train Epoch: 16 [40000/50000 (80%)]\tLoss: 0.034271\n",
      "\n",
      "Average loss: 0.0553, Accuracy: 9840/10000 (98.4000%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.028307\n",
      "Train Epoch: 17 [10000/50000 (20%)]\tLoss: 0.034873\n",
      "Train Epoch: 17 [20000/50000 (40%)]\tLoss: 0.038309\n",
      "Train Epoch: 17 [30000/50000 (60%)]\tLoss: 0.037160\n",
      "Train Epoch: 17 [40000/50000 (80%)]\tLoss: 0.034134\n",
      "\n",
      "Average loss: 0.0493, Accuracy: 9859/10000 (98.5900%)\n",
      "\n",
      "best valid_acc 98.59\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.029892\n",
      "Train Epoch: 18 [10000/50000 (20%)]\tLoss: 0.046860\n",
      "Train Epoch: 18 [20000/50000 (40%)]\tLoss: 0.028087\n",
      "Train Epoch: 18 [30000/50000 (60%)]\tLoss: 0.029802\n",
      "Train Epoch: 18 [40000/50000 (80%)]\tLoss: 0.029630\n",
      "\n",
      "Average loss: 0.0474, Accuracy: 9865/10000 (98.6500%)\n",
      "\n",
      "best valid_acc 98.65\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.037260\n",
      "Train Epoch: 19 [10000/50000 (20%)]\tLoss: 0.044141\n",
      "Train Epoch: 19 [20000/50000 (40%)]\tLoss: 0.041111\n",
      "Train Epoch: 19 [30000/50000 (60%)]\tLoss: 0.032906\n",
      "Train Epoch: 19 [40000/50000 (80%)]\tLoss: 0.036534\n",
      "\n",
      "Average loss: 0.0473, Accuracy: 9862/10000 (98.6200%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.026299\n",
      "Train Epoch: 20 [10000/50000 (20%)]\tLoss: 0.026904\n",
      "Train Epoch: 20 [20000/50000 (40%)]\tLoss: 0.023246\n",
      "Train Epoch: 20 [30000/50000 (60%)]\tLoss: 0.018387\n",
      "Train Epoch: 20 [40000/50000 (80%)]\tLoss: 0.044118\n",
      "\n",
      "Average loss: 0.0488, Accuracy: 9857/10000 (98.5700%)\n",
      "\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.042192\n",
      "Train Epoch: 21 [10000/50000 (20%)]\tLoss: 0.034686\n",
      "Train Epoch: 21 [20000/50000 (40%)]\tLoss: 0.037195\n",
      "Train Epoch: 21 [30000/50000 (60%)]\tLoss: 0.027731\n",
      "Train Epoch: 21 [40000/50000 (80%)]\tLoss: 0.033188\n",
      "\n",
      "Average loss: 0.0468, Accuracy: 9870/10000 (98.7000%)\n",
      "\n",
      "best valid_acc 98.7\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.023785\n",
      "Train Epoch: 22 [10000/50000 (20%)]\tLoss: 0.030446\n",
      "Train Epoch: 22 [20000/50000 (40%)]\tLoss: 0.026625\n",
      "Train Epoch: 22 [30000/50000 (60%)]\tLoss: 0.021679\n",
      "Train Epoch: 22 [40000/50000 (80%)]\tLoss: 0.022796\n",
      "\n",
      "Average loss: 0.0490, Accuracy: 9862/10000 (98.6200%)\n",
      "\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.024969\n",
      "Train Epoch: 23 [10000/50000 (20%)]\tLoss: 0.042774\n",
      "Train Epoch: 23 [20000/50000 (40%)]\tLoss: 0.031845\n",
      "Train Epoch: 23 [30000/50000 (60%)]\tLoss: 0.025547\n",
      "Train Epoch: 23 [40000/50000 (80%)]\tLoss: 0.031051\n",
      "\n",
      "Average loss: 0.0451, Accuracy: 9874/10000 (98.7400%)\n",
      "\n",
      "best valid_acc 98.74000000000001\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.030705\n",
      "Train Epoch: 24 [10000/50000 (20%)]\tLoss: 0.025776\n",
      "Train Epoch: 24 [20000/50000 (40%)]\tLoss: 0.021090\n",
      "Train Epoch: 24 [30000/50000 (60%)]\tLoss: 0.023809\n",
      "Train Epoch: 24 [40000/50000 (80%)]\tLoss: 0.033332\n",
      "\n",
      "Average loss: 0.0453, Accuracy: 9873/10000 (98.7300%)\n",
      "\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.025335\n",
      "Train Epoch: 25 [10000/50000 (20%)]\tLoss: 0.023521\n",
      "Train Epoch: 25 [20000/50000 (40%)]\tLoss: 0.025527\n",
      "Train Epoch: 25 [30000/50000 (60%)]\tLoss: 0.018244\n",
      "Train Epoch: 25 [40000/50000 (80%)]\tLoss: 0.033597\n",
      "\n",
      "Average loss: 0.0483, Accuracy: 9869/10000 (98.6900%)\n",
      "\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.018098\n",
      "Train Epoch: 26 [10000/50000 (20%)]\tLoss: 0.021040\n",
      "Train Epoch: 26 [20000/50000 (40%)]\tLoss: 0.022109\n",
      "Train Epoch: 26 [30000/50000 (60%)]\tLoss: 0.036759\n",
      "Train Epoch: 26 [40000/50000 (80%)]\tLoss: 0.035879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.0441, Accuracy: 9885/10000 (98.8500%)\n",
      "\n",
      "best valid_acc 98.85000000000001\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.013561\n",
      "Train Epoch: 27 [10000/50000 (20%)]\tLoss: 0.016255\n",
      "Train Epoch: 27 [20000/50000 (40%)]\tLoss: 0.021542\n",
      "Train Epoch: 27 [30000/50000 (60%)]\tLoss: 0.030426\n",
      "Train Epoch: 27 [40000/50000 (80%)]\tLoss: 0.027197\n",
      "\n",
      "Average loss: 0.0431, Accuracy: 9882/10000 (98.8200%)\n",
      "\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.021733\n",
      "Train Epoch: 28 [10000/50000 (20%)]\tLoss: 0.020030\n",
      "Train Epoch: 28 [20000/50000 (40%)]\tLoss: 0.021775\n",
      "Train Epoch: 28 [30000/50000 (60%)]\tLoss: 0.011013\n",
      "Train Epoch: 28 [40000/50000 (80%)]\tLoss: 0.031070\n",
      "\n",
      "Average loss: 0.0441, Accuracy: 9881/10000 (98.8100%)\n",
      "\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.015416\n",
      "Train Epoch: 29 [10000/50000 (20%)]\tLoss: 0.013952\n",
      "Train Epoch: 29 [20000/50000 (40%)]\tLoss: 0.018314\n",
      "Train Epoch: 29 [30000/50000 (60%)]\tLoss: 0.016735\n",
      "Train Epoch: 29 [40000/50000 (80%)]\tLoss: 0.017252\n",
      "\n",
      "Average loss: 0.0452, Accuracy: 9878/10000 (98.7800%)\n",
      "\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.010544\n",
      "Train Epoch: 30 [10000/50000 (20%)]\tLoss: 0.024932\n",
      "Train Epoch: 30 [20000/50000 (40%)]\tLoss: 0.011474\n",
      "Train Epoch: 30 [30000/50000 (60%)]\tLoss: 0.021395\n",
      "Train Epoch: 30 [40000/50000 (80%)]\tLoss: 0.026326\n",
      "\n",
      "Average loss: 0.0442, Accuracy: 9877/10000 (98.7700%)\n",
      "\n",
      "\n",
      "Average loss: 0.0391, Accuracy: 9878/10000 (98.7800%)\n",
      "\n",
      "final test acc 98.78\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "  train(epoch, model, train_loader) # 1 epoch 학습\n",
    "  valid_acc = evaluate(model, valid_loader) # 1 epoch 학습 후 validation 수행\n",
    "  # validation 한 뒤에, validation accuracy를 갱신할 때 마다 best model로 따로 저장 \n",
    "  if valid_acc >= best_valid_acc:\n",
    "    best_valid_acc = valid_acc\n",
    "    best_model = copy.deepcopy(model)\n",
    "    print('best valid_acc', best_valid_acc * 100.)\n",
    "\n",
    "# Best Model을 Test Dataset으로 Accuracy 측정\n",
    "eval_acc = evaluate(best_model, test_loader)\n",
    "print('final test acc', eval_acc * 100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.0371, Accuracy: 9885/10000 (98.8500%)\n",
      "\n",
      "final test acc 98.85000000000001\n"
     ]
    }
   ],
   "source": [
    "# 가장 마지막 모델로도 test 수행\n",
    "eval_acc = evaluate(model, test_loader)\n",
    "print('final test acc', eval_acc * 100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 5, 5])\n",
      "torch.Size([8])\n",
      "torch.Size([16, 8, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n",
      "11274\n"
     ]
    }
   ],
   "source": [
    "# 모델의 파라메터 갯수 카운트\n",
    "param_count = 0\n",
    "for param in model.parameters():\n",
    "  print(param.data.shape)\n",
    "  param_count += np.product(param.data.shape)\n",
    "print(param_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnEEvSZ0z6CWpc/8fj7h8Dkt/BkkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffaed14ef28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 초기화 당시의 모델(학습 안된 것) weights이 갖고 있는 값들을 histogram으로 확인\n",
    "orig_params = []\n",
    "for param in orig_model.parameters():\n",
    "  orig_params.append(param.data.cpu().numpy().flatten())\n",
    "orig_params_flat = np.concatenate(orig_params)\n",
    "_ = plt.hist(orig_params_flat, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffaed041828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습이 끝난 뒤, weights 들이 갖고 있는 값의 분포를 histogram으로 확인\n",
    "final_params = []\n",
    "for param in best_model.parameters():\n",
    "  final_params.append(param.data.cpu().numpy().flatten())\n",
    "final_params_flat = np.concatenate(final_params)\n",
    "_ = plt.hist(final_params_flat, bins=200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
